{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de7bac8",
   "metadata": {},
   "source": [
    "# Metagenomic Binning\n",
    "\n",
    "This notebook will go through the workflow for binning contigs into species-level bins from a metagenome assembled genome (MAG).\n",
    "\n",
    "1. Create bins for your megahit MAGs\n",
    "2. Create bins for your metaspades MAGs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ebed36",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "You will need to rerun this section each time you come back to this notebook to reset all directories and variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a46521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the variables for your netid and xfile\n",
    "netid = \"MY_NETID\"\n",
    "xfile = \"MY_XFILE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d388ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go into the working directory\n",
    "work_dir = \"/xdisk/bhurwitz/bh_class/\" + netid + \"/assignments/09_metag_binning\"\n",
    "%cd $work_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380dffed",
   "metadata": {},
   "source": [
    "## Creating a config file\n",
    "The scripts below executes code that requires certain variables to be set. So we don't need to edit the code in the script, we are going to use a config file that defines all of these variables for us. Then when we want to use these variables in the script, we will \"source\" the config file to set the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049cf341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a config file with all of the variables you need\n",
    "# notice that we are using the reads post-trimming, and post-human removal\n",
    "!echo \"export NETID=$netid\" > config.sh\n",
    "!echo \"export XFILE=$xfile\" >> config.sh\n",
    "!echo \"export WORK_DIR=/xdisk/bhurwitz/bh_class/$netid/assignments/09_metag_binning\" >> config.sh\n",
    "!echo \"export XFILE_DIR=/xdisk/bhurwitz/bh_class/$netid/assignments/05_getting_data\" >> config.sh\n",
    "!echo \"export FASTQ_DIR=/xdisk/bhurwitz/bh_class/$netid/assignments/07_contam_removal\" >> config.sh\n",
    "!echo \"export MEGAHIT_DIR=/xdisk/bhurwitz/bh_class/$netid/assignments/08_assembly/out_megahit\" >> config.sh\n",
    "!echo \"export METASPADES_DIR=/xdisk/bhurwitz/bh_class/$netid/assignments/08_assembly/out_metaspades\" >> config.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1996dcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the config file to be sure it is correct\n",
    "# Is your netid and xfile correct? Do you have the right directories?\n",
    "!cat config.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeaabfe",
   "metadata": {},
   "source": [
    "## Step 1: Binning contigs from your Megahit Assembly\n",
    "\n",
    "In this step, we will create species-level bins for the contigs that were created from our megahit assembly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7e3021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a script to run maxbin to bin megahit contigs by species\n",
    "# A few important points:\n",
    "# 1. We are using the variables from the config file via the `source ./config.sh` command in the script.\n",
    "# 2. maxbin runs on each of the fastq files in the trimmed $FASTQ_DIR\n",
    "# 3. The results will be written into our $WORK_DIR\n",
    "# 4. Notice that we are asking for alot more resource (24 cores and 5G of memory per core), we are also asking for more time (24 hours)\n",
    "my_code = '''#!/bin/bash\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --nodes=1             \n",
    "#SBATCH --time=24:00:00   \n",
    "#SBATCH --partition=standard\n",
    "#SBATCH --account=bh_class\n",
    "#SBATCH --array=0-4                         \n",
    "#SBATCH --output=Job-mega-bins-%a.out\n",
    "#SBATCH --cpus-per-task=24\n",
    "#SBATCH --mem-per-cpu=5G                                    \n",
    "\n",
    "pwd; hostname; date\n",
    "\n",
    "source ./config.sh\n",
    "names=($(cat $XFILE_DIR/$XFILE))\n",
    "\n",
    "SAMPLE_ID=${names[${SLURM_ARRAY_TASK_ID}]}\n",
    "\n",
    "### reads after trimming and human filtering\n",
    "PAIR1=${FASTQ_DIR}/${SAMPLE_ID}_1.fastq*\n",
    "PAIR2=${FASTQ_DIR}/${SAMPLE_ID}_2.fastq*\n",
    "\n",
    "MEGAHIT_OUTDIR=${WORK_DIR}/out_megahit\n",
    "OUTDIR=${MEGAHIT_OUTDIR}/${SAMPLE_ID}\n",
    "\n",
    "### create the outdir if it does not exist\n",
    "if [[ ! -d \"$MEGAHIT_OUTDIR\" ]]; then\n",
    "  echo \"$MEGAHIT_OUTDIR does not exist. Directory created\"\n",
    "  mkdir $MEGAHIT_OUTDIR\n",
    "fi\n",
    "\n",
    "if [[ ! -d \"$OUTDIR\" ]]; then\n",
    "  echo \"$OUTDIR does not exist. Directory created\"\n",
    "  mkdir $OUTDIR\n",
    "fi\n",
    "\n",
    "### final contigs\n",
    "CONTIGS=\"${MEGAHIT_DIR}/${SAMPLE_ID}/final_contigs.fa\"\n",
    "\n",
    "/contrib/singularity/shared/bhurwitz/maxbin2:2.2.7--hdbdd923_5.sif run_MaxBin.pl \\\n",
    "-thread 24 -contig ${CONTIGS} \\\n",
    "-reads ${PAIR1} \\\n",
    "-reads2 ${PAIR2} \\\n",
    "-out ${OUTDIR}\n",
    "\n",
    "'''\n",
    "\n",
    "with open('megahit_bin_parallel.sh', mode='w') as file:\n",
    "    file.write(my_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231b9374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the code and make sure your script above was created.\n",
    "!cat megahit_bin_parallel.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e42306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you should be in your working directory when you run this script\n",
    "# do you see your config.sh file, and the megahit_bin_parallel.sh script?\n",
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe884278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run sbatch to run the megahit contig binning\n",
    "# Remember that this may take a while to run, so take a break, and get a coffee.\n",
    "!sbatch ./megahit_bin_parallel.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3699608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can check if it is running using the squeue command\n",
    "# Check for all jobs under your netid\n",
    "!squeue --user=$netid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e70ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once your jobs have run (or are running) you can check the progress\n",
    "# and also look for errors in the *out files\n",
    "# For example, you can look at Job-mega-bins-0.out\n",
    "!ls\n",
    "!cat Job-mega-bins-0.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d7e85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check that you have bins for your contigs from megahit\n",
    "!ls $work_dir/out_megahit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b30b51",
   "metadata": {},
   "source": [
    "Rock on! You have created bins for your megahit contigs. These bins should represent the species present in your samples.\n",
    "\n",
    "This will generate a series of files. Take a look at the files generated. In particular you should see a series of *.fasta files preceeded by numbers. These are the different genome bins predicted by MaxBin.\n",
    "\n",
    "Take a look at the mbin.summary file. What is shown?\n",
    "\n",
    "Now, we are going to generate a concatenated file that contains all of our genome bins put together. We will change the fasta header name to include the bin number so that we can tell them apart later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0ef256",
   "metadata": {},
   "outputs": [],
   "source": [
    "!for file in mbin.*.fasta; do; num=${file//[!0-9]/} ; sed -e \"/^>/ s/$/ ${num}/\" mbin.$num.fasta >> maxbin_binned.concat.fasta ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413c459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a script to run maxbin to bin metaspades contigs by species\n",
    "# A few important points:\n",
    "# 1. We are using the variables from the config file via the `source ./config.sh` command in the script.\n",
    "# 2. maxbin runs on each of the fastq files in the trimmed $FASTQ_DIR\n",
    "# 3. The results will be written into our $WORK_DIR\n",
    "# 4. Notice that we are asking for alot more resource (24 cores and 5G of memory per core), we are also asking for more time (24 hours)\n",
    "my_code = '''#!/bin/bash\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --nodes=1             \n",
    "#SBATCH --time=24:00:00   \n",
    "#SBATCH --partition=standard\n",
    "#SBATCH --account=bh_class\n",
    "#SBATCH --array=0-4                         \n",
    "#SBATCH --output=Job-metaspades-bins-%a.out\n",
    "#SBATCH --cpus-per-task=24\n",
    "#SBATCH --mem-per-cpu=5G                                    \n",
    "\n",
    "pwd; hostname; date\n",
    "\n",
    "source ./config.sh\n",
    "names=($(cat $XFILE_DIR/$XFILE))\n",
    "\n",
    "SAMPLE_ID=${names[${SLURM_ARRAY_TASK_ID}]}\n",
    "\n",
    "### reads after trimming and human filtering\n",
    "PAIR1=${FASTQ_DIR}/${SAMPLE_ID}_1.fastq*\n",
    "PAIR2=${FASTQ_DIR}/${SAMPLE_ID}_2.fastq*\n",
    "\n",
    "METASPADES_OUTDIR=${WORK_DIR}/out_metaspades\n",
    "OUTDIR=${METASPADES_OUTDIR}/${SAMPLE_ID}\n",
    "\n",
    "### create the outdir if it does not exist\n",
    "if [[ ! -d \"$METASPADES_OUTDIR\" ]]; then\n",
    "  echo \"$METASPADES_OUTDIR does not exist. Directory created\"\n",
    "  mkdir $METASPADES_OUTDIR\n",
    "fi\n",
    "\n",
    "if [[ ! -d \"$OUTDIR\" ]]; then\n",
    "  echo \"$OUTDIR does not exist. Directory created\"\n",
    "  mkdir $OUTDIR\n",
    "fi\n",
    "\n",
    "### final contigs\n",
    "CONTIGS=\"${METASPADES_DIR}/${SAMPLE_ID}/contigs.fasta\"\n",
    "\n",
    "/contrib/singularity/shared/bhurwitz/maxbin2:2.2.7--hdbdd923_5.sif run_MaxBin.pl \\\n",
    "-thread 24 -contig ${CONTIGS} \\\n",
    "-reads ${PAIR1} \\\n",
    "-reads2 ${PAIR2} \\\n",
    "-out ${OUTDIR}\n",
    "\n",
    "'''\n",
    "\n",
    "with open('metaspades_bin_parallel.sh', mode='w') as file:\n",
    "    file.write(my_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83501ab5",
   "metadata": {},
   "source": [
    "## Final Step\n",
    "Copy your notebook to the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b6190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp ~/07_contam_removal.ipynb $work_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
